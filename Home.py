"""
AI Content Marketing Optimization Platform
Main entry point for multi-page Streamlit app
"""

import streamlit as st
import pandas as pd
from utils.styles import get_custom_css
from utils.backend import (
    get_predictor, get_simulator, get_coach,
    load_twitter_data, load_reddit_data,
    get_last_30_days_data
)
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime

# Page config
st.set_page_config(
    page_title="AI Content Marketing Platform",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Apply custom CSS
st.markdown(get_custom_css(), unsafe_allow_html=True)

# Header with refresh button
col_title, col_refresh = st.columns([5, 1])

with col_title:
    st.markdown('<h1 class="main-header">ğŸš€ AI Content Marketing Optimization Platform</h1>', unsafe_allow_html=True)
    st.markdown("### Powered by Google Gemini - AI-Driven Social Media Analytics")

with col_refresh:
    st.markdown("<br>", unsafe_allow_html=True)  # Spacing
    if st.button("ğŸ”„ Refresh Data", key="top_refresh_btn", help="Clear cache and reload fresh data"):
        st.cache_data.clear()
        st.rerun()

st.markdown('<div class="divider"></div>', unsafe_allow_html=True)

# ==================== QUICK START GUIDE ====================
st.markdown('<h2 class="page-title">ğŸ¯ Get Started</h2>', unsafe_allow_html=True)

quick_col1, quick_col2 = st.columns(2)

with quick_col1:
    st.markdown("""
    ### âœï¸ Generate Content
    Use our AI-powered tools to create and optimize marketing content:
    
    1. **Content Optimizer** - Improve existing content with smart variants
    2. **Topic Content Generator** - Create fresh content about any topic
       - Collect Reddit data about your topic
       - Train Gemini AI on the data
       - Generate optimized marketing content
    """)
    
    if st.button("ğŸš€ Go to Topic Generator", use_container_width=True):
        st.switch_page("pages/8_âœï¸_Topic_Content_Generator.py")

with quick_col2:
    st.markdown("""
    ### ğŸ“Š Analyze Performance
    Review your social media performance and insights:
    
    1. **Performance Dashboard** - Overview of all metrics
    2. **Engagement Predictor** - Predict post performance
    3. **Campaign Simulator** - Test campaign strategies
    """)
    
    if st.button("ğŸ“ˆ Go to Dashboard", use_container_width=True):
        st.switch_page("pages/2_ğŸ“Š_Performance_Dashboard.py")

st.markdown('<div class="divider"></div>', unsafe_allow_html=True)

# Initialize backend (cached)
try:
    predictor = get_predictor()
    simulator = get_simulator()
    coach = get_coach()
except Exception as e:
    st.error(f"âš ï¸ Error initializing backend: {e}")
    st.stop()

# Load data
with st.spinner("ğŸ“Š Loading data..."):
    twitter_df = load_twitter_data()
    reddit_df = load_reddit_data()

# Convert created_at to datetime for both dataframes
for df in [twitter_df, reddit_df]:
    if 'created_at' in df.columns:
        df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce', utc=True)

# Ensure engagement columns exist before filtering
if len(twitter_df) > 0:
    if 'likes' not in twitter_df.columns:
        twitter_df['likes'] = 0
    if 'retweets' not in twitter_df.columns:
        twitter_df['retweets'] = 0
    if 'replies' not in twitter_df.columns:
        twitter_df['replies'] = 0
        
    twitter_df['likes'] = pd.to_numeric(twitter_df['likes'], errors='coerce').fillna(0)
    twitter_df['retweets'] = pd.to_numeric(twitter_df['retweets'], errors='coerce').fillna(0)
    twitter_df['replies'] = pd.to_numeric(twitter_df['replies'], errors='coerce').fillna(0)
    
    if 'engagement' not in twitter_df.columns:
        twitter_df['engagement'] = twitter_df['likes'] + twitter_df['retweets'] + twitter_df['replies']
    else:
        twitter_df['engagement'] = pd.to_numeric(twitter_df['engagement'], errors='coerce').fillna(0)

if len(reddit_df) > 0:
    if 'score' not in reddit_df.columns:
        reddit_df['score'] = 0
    if 'num_comments' not in reddit_df.columns:
        reddit_df['num_comments'] = 0
        
    reddit_df['score'] = pd.to_numeric(reddit_df['score'], errors='coerce').fillna(0)
    reddit_df['num_comments'] = pd.to_numeric(reddit_df['num_comments'], errors='coerce').fillna(0)
    
    if 'engagement' not in reddit_df.columns:
        reddit_df['engagement'] = reddit_df['score'] + reddit_df['num_comments']
    else:
        reddit_df['engagement'] = pd.to_numeric(reddit_df['engagement'], errors='coerce').fillna(0)

# Filter to last 30 days
twitter_30d = get_last_30_days_data(twitter_df)
reddit_30d = get_last_30_days_data(reddit_df, 'created_at')

# Debug info if data is empty but source has data
if len(twitter_df) > 0 and len(twitter_30d) == 0:
    st.info("ğŸ“Š Twitter data exists but no posts from the last 30 days. Run data collection to get fresh data!")
    # Show all data instead of just 30 days
    twitter_30d = twitter_df.copy()

# ==================== KPI METRICS ====================
st.markdown('<h2 class="page-title">ğŸ“Š 30-Day Performance Summary</h2>', unsafe_allow_html=True)

col1, col2, col3, col4 = st.columns(4)

with col1:
    twitter_count = len(twitter_30d)
    st.metric(
        label="ğŸ¦ Twitter Posts",
        value=f"{twitter_count:,}",
        delta=f"+{int(twitter_count * 0.15)}" if twitter_count > 0 else "0"
    )

with col2:
    reddit_count = len(reddit_30d)
    st.metric(
        label="ğŸ”´ Reddit Posts",
        value=f"{reddit_count:,}",
        delta=f"+{int(reddit_count * 0.12)}" if reddit_count > 0 else "0"
    )

with col3:
    if len(twitter_30d) > 0 and 'engagement' in twitter_30d.columns:
        avg_engagement = twitter_30d['engagement'].mean()
        st.metric(
            label="ğŸ’¬ Avg Engagement",
            value=f"{avg_engagement:.1f}",
            delta=f"+{avg_engagement * 0.08:.1f}"
        )
    else:
        st.metric(label="ğŸ’¬ Avg Engagement", value="0", delta="0")

with col4:
    if len(twitter_30d) > 0 and 'engagement' in twitter_30d.columns:
        total_engagement = twitter_30d['engagement'].sum()
    else:
        total_engagement = 0
    
    st.metric(
        label="ğŸ”¥ Total Engagement",
        value=f"{int(total_engagement):,}",
        delta=f"+{int(total_engagement * 0.1)}" if total_engagement > 0 else "0"
    )

st.markdown('<div class="divider"></div>', unsafe_allow_html=True)

# ==================== CHARTS ====================
if len(twitter_30d) > 0:
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown('<h3 class="section-header">â° Best Posting Times</h3>', unsafe_allow_html=True)
        
        # Hour analysis
        twitter_30d['hour'] = twitter_30d['created_at'].dt.hour
        hourly_data = twitter_30d.groupby('hour')['engagement'].mean().reset_index()
        hourly_data = hourly_data.sort_values('engagement', ascending=False).head(10)
        
        fig = px.bar(
            hourly_data, 
            x='hour', 
            y='engagement',
            title='Top 10 Hours by Average Engagement',
            labels={'hour': 'Hour of Day', 'engagement': 'Avg Engagement'},
            color='engagement',
            color_continuous_scale='Viridis'
        )
        fig.update_layout(
            template='plotly_dark',
            showlegend=False,
            height=350
        )
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.markdown('<h3 class="section-header">ğŸ“ˆ Engagement Trend</h3>', unsafe_allow_html=True)
        
        # Daily engagement trend
        daily_data = twitter_30d.groupby(twitter_30d['created_at'].dt.date)['engagement'].sum().reset_index()
        daily_data.columns = ['Date', 'Engagement']
        
        fig = px.area(
            daily_data,
            x='Date',
            y='Engagement',
            title='Daily Engagement Over Last 30 Days',
            color_discrete_sequence=['#667eea']
        )
        fig.update_layout(
            template='plotly_dark',
            showlegend=False,
            height=350
        )
        st.plotly_chart(fig, use_container_width=True)
    
    # Sentiment trend (if available)
    st.markdown('<h3 class="section-header">ğŸ˜Š Sentiment Trend (30 Days)</h3>', unsafe_allow_html=True)
    
    # Calculate sentiment scores
    if 'text' in twitter_30d.columns:
        from textblob import TextBlob
        
        def get_sentiment(text):
            try:
                return TextBlob(str(text)).sentiment.polarity
            except:
                return 0
        
        twitter_30d['sentiment'] = twitter_30d['text'].apply(get_sentiment)
        twitter_30d['sentiment_category'] = twitter_30d['sentiment'].apply(
            lambda x: 'Positive' if x > 0.1 else 'Negative' if x < -0.1 else 'Neutral'
        )
        
        # Daily sentiment
        daily_sentiment = twitter_30d.groupby(twitter_30d['created_at'].dt.date)['sentiment'].mean().reset_index()
        daily_sentiment.columns = ['Date', 'Sentiment']
        
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=daily_sentiment['Date'],
            y=daily_sentiment['Sentiment'],
            mode='lines+markers',
            line=dict(color='#2ecc71', width=3),
            fill='tozeroy',
            fillcolor='rgba(46, 204, 113, 0.2)',
            name='Sentiment Score'
        ))
        fig.update_layout(
            title='Average Daily Sentiment Score',
            template='plotly_dark',
            height=300,
            xaxis_title='Date',
            yaxis_title='Sentiment Score'
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # Sentiment distribution
        col1, col2 = st.columns([1, 2])
        
        with col1:
            sentiment_counts = twitter_30d['sentiment_category'].value_counts()
            
            fig = go.Figure(data=[go.Pie(
                labels=sentiment_counts.index,
                values=sentiment_counts.values,
                marker_colors=['#2ecc71', '#95a5a6', '#e74c3c'],
                hole=0.4
            )])
            fig.update_layout(
                title='Sentiment Distribution',
                template='plotly_dark',
                height=300
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            st.markdown('<div class="info-box">', unsafe_allow_html=True)
            st.markdown("**ğŸ“Š Sentiment Insights:**")
            
            positive_pct = (sentiment_counts.get('Positive', 0) / len(twitter_30d)) * 100
            neutral_pct = (sentiment_counts.get('Neutral', 0) / len(twitter_30d)) * 100
            negative_pct = (sentiment_counts.get('Negative', 0) / len(twitter_30d)) * 100
            
            st.markdown(f"""
            - **Positive Posts:** {positive_pct:.1f}% ({sentiment_counts.get('Positive', 0)} posts)
            - **Neutral Posts:** {neutral_pct:.1f}% ({sentiment_counts.get('Neutral', 0)} posts)
            - **Negative Posts:** {negative_pct:.1f}% ({sentiment_counts.get('Negative', 0)} posts)
            
            **ğŸ’¡ Recommendation:**
            {
                "Keep up the positive tone! Your audience responds well to optimistic content." if positive_pct > 50
                else "Consider adding more positive language to boost engagement." if positive_pct < 30
                else "Good balance of sentiment. Maintain variety in your content tone."
            }
            """)
            st.markdown('</div>', unsafe_allow_html=True)

else:
    st.info("ğŸ“Š No data available for the last 30 days. Run data collection to get started!")
    
    st.markdown('<div class="info-box">', unsafe_allow_html=True)
    st.markdown("""
    ### ğŸš€ Getting Started
    
    Collect fresh data from Twitter and Reddit to populate your dashboard with insights and analytics.
    
    **What you'll get:**
    - Latest tweets and engagement metrics
    - Reddit posts from trending subreddits
    - Sentiment analysis
    - Temporal trends
    - Historical data for predictions
    """)
    st.markdown('</div>', unsafe_allow_html=True)
    
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
    
    # Data collection button
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col2:
        if st.button("ğŸš€ Start Data Collection", key="collect_data_btn", use_container_width=True):
            import subprocess
            import sys
            
            st.markdown('<div class="info-box">', unsafe_allow_html=True)
            st.markdown("### ğŸ“¡ Collecting Data...")
            
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            try:
                # Update progress
                status_text.text("â³ Starting data collection process...")
                progress_bar.progress(10)
                
                # Run main.py in the background
                status_text.text("ğŸ¦ Fetching Twitter data...")
                progress_bar.progress(30)
                
                result = subprocess.run(
                    [sys.executable, "main.py"],
                    capture_output=True,
                    text=True,
                    timeout=300  # 5 minute timeout
                )
                
                progress_bar.progress(80)
                status_text.text("âœ… Processing collected data...")
                
                if result.returncode == 0:
                    progress_bar.progress(100)
                    status_text.text("")
                    
                    # Clear all cached data to force reload
                    st.cache_data.clear()
                    
                    st.success("âœ… Data collection completed successfully!")
                    st.markdown("""
                    **Data Updated! Refreshing dashboard...**
                    
                    The page will automatically reload with fresh data in 2 seconds.
                    """)
                    
                    # Auto-refresh after 2 seconds
                    st.markdown("""
                    <script>
                        setTimeout(function() {
                            window.location.reload();
                        }, 2000);
                    </script>
                    """, unsafe_allow_html=True)
                    
                    # Manual refresh button as backup
                    if st.button("ğŸ”„ Refresh Now", key="refresh_now_btn"):
                        st.rerun()
                else:
                    st.error(f"âŒ Data collection failed: {result.stderr}")
                    
            except subprocess.TimeoutExpired:
                st.warning("âš ï¸ Data collection is taking longer than expected. It's running in the background.")
            except Exception as e:
                st.error(f"âŒ Error during data collection: {str(e)}")
            
            st.markdown('</div>', unsafe_allow_html=True)
    
    st.markdown('<div class="divider"></div>', unsafe_allow_html=True)
    
    # Alternative manual method
    st.markdown('<div class="info-box">', unsafe_allow_html=True)
    st.markdown("""
    ### ğŸ’» Alternative: Manual Data Collection
    
    You can also run data collection from your terminal:
    
    ```bash
    python main.py
    ```
    
    **Quick Links:**
    - ğŸ”® Content Generator â†’ Create AI-powered content variants
    - ğŸ§ª A/B Testing Lab â†’ Test and compare content performance
    - ğŸ¤– Engagement Coach â†’ Get personalized recommendations
    - ğŸ“‹ Campaign Simulator â†’ Plan optimal posting schedules
    """)
    st.markdown('</div>', unsafe_allow_html=True)

# ==================== FOOTER ====================
st.markdown('<div class="divider"></div>', unsafe_allow_html=True)

st.markdown("""
<div style="text-align: center; padding: 20px;">
    <p style="color: #667eea; font-weight: bold;">
        ğŸ¤– Powered by Google Gemini â€¢ ğŸ“Š Google Sheets Integration â€¢ ğŸ’¬ Slack Notifications
    </p>
    <p style="color: #888; font-size: 0.9rem;">
        Built with â¤ï¸ using Streamlit â€¢ Last Updated: {date}
    </p>
</div>
""".format(date=datetime.now().strftime('%Y-%m-%d %H:%M')), unsafe_allow_html=True)
