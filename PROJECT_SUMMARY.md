# ğŸ“Š Social Media Data Collection & Analysis Project - Summary

**Project Name:** Social Media Data Collection, Analysis & Content Generation  
**Date Updated:** November 11, 2025  
**Status:** âœ… Production Ready - Milestones 1, 2 & 3 Complete

---

## ğŸ¯ Project Overview

This project automatically collects data from multiple social media platforms (Twitter/X with multi-account rotation, Reddit, Google Trends), performs comprehensive exploratory data analysis (EDA) with sentiment and temporal analysis, generates optimized content using LLM with advanced parameter tuning, and provides actionable business insights. All data is stored in Google Sheets with real-time Slack notifications. The system features separate content generation and optimization workflows with both automatic and manual LLM parameter selection.

**Key Achievements:**
- âœ… **12,587 data points collected** (2,517 Twitter + 10,070 Reddit)
- âœ… **100% complete EDA** with sentiment analysis and temporal trends
- âœ… **Multi-account Twitter rotation** (14 accounts)
- âœ… **LLM-based content generation** (Ollama/Llama 3.2, free & local)
- âœ… **Content optimization** with automatic & manual LLM parameter selection
- âœ… **Dual Google Sheets storage** (Generated_Content + Optimized_Content)
- âœ… **Actionable insights discovered** (6 AM Friday = 10x better engagement)
- âœ… **A/B testing tracker** with variant metrics and winner identification
- âœ… **Real-time performance dashboard** with HTML generation
- âœ… **Automated weekly/monthly reports** with trend analysis
- âœ… **Advanced sentiment analysis** with content recommendations

---

## ğŸ“ Project Structure

```
social_data_project/
â”‚
â”œâ”€â”€ service_account.json          âœ… Google Cloud service account credentials
â”œâ”€â”€ twitter_accounts.json         âœ… Multi-account Twitter configuration (14 accounts)
â”œâ”€â”€ .env                          âœ… API keys and credentials (secure)
â”œâ”€â”€ .gitignore                    âœ… Protects sensitive files
â”œâ”€â”€ requirements.txt              âœ… Python dependencies
â”‚
â”œâ”€â”€ google_sheet_connect.py       âœ… Google Sheets connection module
â”œâ”€â”€ twitter_data.py               âœ… Twitter/X API data fetching
â”œâ”€â”€ twitter_multi_account.py      âœ… Multi-account rotation system
â”œâ”€â”€ reddit_data.py                âœ… Reddit API data fetching
â”œâ”€â”€ trends_data.py                âœ… Google Trends data fetching
â”œâ”€â”€ slack_notify.py               âœ… Slack notification module
â”œâ”€â”€ write_to_sheet.py             âœ… Data writing module
â”œâ”€â”€ main.py                       âœ… Main orchestration script
â”‚
â”œâ”€â”€ data_analysis.py              âœ… Comprehensive EDA with sentiment & temporal analysis
â”œâ”€â”€ llm_content_generator.py      âœ… LLM content generation (saves to sheets + Slack)
â”œâ”€â”€ content_optimizer.py          âœ… Content optimization (automatic & manual params + sheets + Slack)
â”‚
â”œâ”€â”€ ab_testing_tracker.py         âœ… A/B testing tracker with winner identification (Milestone 3)
â”œâ”€â”€ performance_dashboard.py      âœ… Performance dashboard with HTML generation (Milestone 3)
â”œâ”€â”€ automated_reports.py          âœ… Weekly/monthly automated reports (Milestone 3)
â”œâ”€â”€ advanced_sentiment_analysis.py âœ… Advanced sentiment analysis system (Milestone 3)
â”‚
â”œâ”€â”€ README.md                     âœ… Setup and usage documentation
â”œâ”€â”€ PROJECT_SUMMARY.md            ğŸ“„ This file (technical overview)
â”œâ”€â”€ MILESTONE3_GUIDE.md           âœ… Milestone 3 features guide
â”œâ”€â”€ KEY_INSIGHTS.md               âœ… Data analysis findings & recommendations
â”œâ”€â”€ QUICK_ACTION_CARD.md          âœ… Quick reference guide for content strategy
â”œâ”€â”€ SLACK_INTEGRATION.md          âœ… Slack setup guide
â”œâ”€â”€ REDDIT_SETUP.md               âœ… Reddit API setup guide
â”œâ”€â”€ TWITTER_MULTI_ACCOUNT_SETUP.md âœ… Multi-account Twitter setup guide
â””â”€â”€ OLLAMA_SETUP.md               âœ… LLM setup guide (Ollama installation)
```

---

## âœ… What's Working

### 1. **Google Sheets Integration** âœ…
- Successfully connected to Google Sheets API
- Service account authentication configured
- Spreadsheet: [Social_Media_Engagement_Data](https://docs.google.com/spreadsheets/d/1VujT31YHr-gIlE2uWT6DyjPNEQXfAdmy60yTrsCAOYY)
- Automatic worksheet creation for each platform
- Data appending and formatting functionality

### 2. **Twitter/X API Integration** âœ…
- **Multi-account rotation system** with 14 Twitter accounts
- Authentication successful with Twitter API v2
- Bearer token working correctly for all accounts
- Can fetch tweets by search query
- Can fetch tweets from specific users
- Automatic rate limit handling and account rotation
- Extracts: tweet text, author info, engagement metrics, timestamps
- **Achievement: 2,517 tweets collected**

### 3. **Reddit API Integration** âœ…
- PRAW (Python Reddit API Wrapper) configured
- Subreddit post fetching working perfectly
- Collects: post titles, content, scores, comments, URLs
- Successfully tested with multiple subreddits
- Rate limit handling (60 requests per minute)
- **Achievement: 10,070 posts collected**

### 4. **Google Trends Integration** âœ…
- Using pytrends library
- Fetches trending searches by region (US, UK, India)
- Collects search volume and trend data
- Used to discover topics for Twitter/Reddit searches
- Note: Aggressive rate limiting (~10-20 requests/hour)

### 5. **Slack Notifications** âœ…
- Real-time notifications via Slack Incoming Webhooks
- Sends success notifications for each platform
- Comprehensive summary after collection completes
- Includes data counts and Google Sheet URL
- Workspace: "Social Data Collection" (#social channel)

### 6. **Data Analysis (NEW!)** âœ…
- **Comprehensive EDA** (100% complete)
  - Missing value analysis
  - Outlier detection (IQR method)
  - Text cleaning and preprocessing
  - Correlation analysis
  - Statistical summaries (min, max, median, mean, std)
- **Sentiment Analysis**
  - TextBlob-based polarity scoring
  - Sentiment classification (Positive/Neutral/Negative)
  - Sentiment-engagement correlation analysis
  - **Key finding: 51.5% neutral, sentiment has minimal impact (-0.030 correlation)**
- **Temporal Trends Analysis**
  - Best posting hours detection
  - Best posting days analysis
  - Weekend vs weekday comparison
  - **Key finding: 6 AM Friday = 10x better engagement**
- **Platform Comparison**
  - **Reddit 2,053x better engagement than Twitter**
  - Optimal content length analysis (50-100 chars = +22% engagement)
  
### 7. **Content Generation** âœ…
- **LLM-based content generator using Ollama**
- Powered by Llama 3.2 (free, local AI model)
- Uses real hashtags from collected data
- Loads high-performing examples from cleaned text
- Generates creative, unique posts for any topic
- **Saves to Google Sheets:** 'Generated_Content' worksheet
- **Sends Slack notifications** for each generation
- **100% free, runs locally, no API costs**
- Fulfills "Implement LLMs" requirement for Milestone 2

### 8. **Content Optimization** âœ…
- **Separate optimization system** with intelligent analysis
- **Automatic LLM parameter selection** (AI-optimized)
  - Temperature: 0.4 (precise for optimization)
  - Top_p: 0.9 (consistent vocabulary)
  - Frequency penalty: 0.3 (natural flow)
  - Presence penalty: 0.2 (stay focused)
- **Manual LLM parameter selection** (user-defined)
  - Interactive prompts for each parameter
  - Validation and guidance provided
  - Custom parameter testing
- **Content analysis & scoring** (0-100 quality score)
  - Length optimization
  - Hashtag analysis
  - Engagement element detection
  - Quality rating system
- **Optimization with both parameter types**
  - Generate with automatic parameters
  - Generate with manual parameters
  - Compare both results
  - Determine winner
- **Saves to Google Sheets:** 'Optimized_Content' worksheet
  - Stores both automatic and manual results
  - Tracks parameters used
  - Records improvement scores
- **Sends Slack notifications** for optimization results
  - Shows original vs optimized content
  - Displays improvement metrics
  - Includes parameter details

### 9. **Data Pipeline** âœ…
- End-to-end data collection working
- Automatic worksheet creation for each platform
- Data appending functionality
- Timestamp tracking (fetched_at column)
- Error handling throughout
- Slack notification integration
- **Total: 12,587 data points collected and analyzed**

---

## ğŸ”§ Technical Details

### APIs Used:
- **Google Sheets API** (via gspread)
- **Twitter API v2** (via tweepy)
- **Reddit API** (via PRAW)
- **Google Trends** (via pytrends)
- **Slack Incoming Webhooks** (via requests)

### Python Version:
- Python 3.13.7

### Key Libraries:
- `gspread==6.2.1` - Google Sheets integration
- `tweepy==4.16.0` - Twitter API client
- `praw==7.8.1` - Reddit API wrapper
- `pytrends==4.9.2` - Google Trends data
- `pandas==2.2.3` - Data manipulation
- `textblob==0.18.0` - Sentiment analysis
- `python-dotenv==1.2.1` - Environment variables
- `google-auth==2.41.1` - Google authentication
- `requests==2.32.3` - Slack webhooks

### Security:
- âœ… Sensitive files in `.gitignore`
- âœ… Credentials stored in `.env` file
- âœ… Service account JSON protected
- âœ… No hardcoded API keys

---

## ğŸ“Š Data Collected

### Twitter Data Fields:
- `fetched_at` - Timestamp when data was collected
- `tweet_id` - Unique tweet identifier
- `created_at` - When the tweet was posted
- `text` - Tweet content
- `author_id` - User ID of author
- `author_username` - Twitter handle
- `author_name` - Display name
- `verified` - Verification status
- `likes` - Like count
- `retweets` - Retweet count
- `replies` - Reply count
- `language` - Tweet language
- `source` - Platform used to post

### Reddit Data Fields:
- `fetched_at` - Timestamp when data was collected
- `post_id` - Unique post identifier
- `created_at` - When the post was created
- `subreddit` - Subreddit name
- `title` - Post title
- `text` - Post content
- `author` - Reddit username
- `score` - Upvote score
- `upvote_ratio` - Ratio of upvotes to downvotes
- `num_comments` - Comment count
- `url` - Post URL
- `permalink` - Full Reddit URL

### Google Trends Data Fields:
- `fetched_at` - Timestamp when data was collected
- `query` - Search term
- `region` - Geographic region
- `value` - Search volume/interest
- `timeframe` - Time period analyzed

---

## ğŸš€ How to Run

### Quick Start:
```powershell
# Run data collection
python main.py

# Run data analysis (after collection)
python data_analysis.py

# Generate AI-powered content based on insights
python llm_content_generator.py
```

### Individual Component Testing:
```powershell
# Test Google Sheets connection
python google_sheet_connect.py

# Test Twitter multi-account system
python twitter_multi_account.py

# Test Reddit API
python reddit_data.py

# Test Google Trends
python trends_data.py

# Test Slack notifications
python slack_notify.py
```

---

## ğŸ”‘ Configuration

### Environment Variables (.env):
```properties
# Twitter API (14 accounts configured)
TWITTER_API_KEY=âœ… Configured
TWITTER_API_SECRET=âœ… Configured
TWITTER_ACCESS_TOKEN=âœ… Configured
TWITTER_ACCESS_SECRET=âœ… Configured
TWITTER_BEARER_TOKEN=âœ… Configured

# Reddit API
REDDIT_CLIENT_ID=âœ… Configured
REDDIT_CLIENT_SECRET=âœ… Configured
REDDIT_USER_AGENT=âœ… Configured

# Slack Webhooks
SLACK_WEBHOOK_URL=âœ… Configured

# Google Sheets
GOOGLE_SHEET_ID=âœ… Configured (1VujT31YHr-gIlE2uWT6DyjPNEQXfAdmy60yTrsCAOYY)
```

### Service Account:
- **Email:** `sheet-access-service@marketingaiproject-476317.iam.gserviceaccount.com`
- **Project:** marketingaiproject-476317
- **Permissions:** Editor access to Google Sheet
- **Status:** âœ… Shared and working

---

## ğŸ“ˆ Features

### Current Features:
- âœ… Automated data collection from Twitter (14 accounts), Reddit, Google Trends
- âœ… Multi-account Twitter rotation system to avoid rate limits
- âœ… **12,587 data points collected** (2,517 Twitter + 10,070 Reddit)
- âœ… Data storage in Google Sheets with automatic formatting
- âœ… Real-time Slack notifications during collection
- âœ… Automatic worksheet creation per platform
- âœ… Timestamp tracking for all data
- âœ… Rate limit handling for all APIs
- âœ… Comprehensive error handling and logging
- âœ… **100% complete EDA module** with sentiment & temporal analysis
- âœ… **Sentiment analysis** (polarity scoring, classification, distribution)
- âœ… **Temporal trends analysis** (best posting times/days)
- âœ… **LLM-based content generation** (Ollama/Llama 3.2, free & local)
- âœ… **A/B test variant generation** (3 tones: professional, casual, inspirational)
- âœ… **7-day content calendar** generation
- âœ… **Actionable insights** documented in KEY_INSIGHTS.md
- âœ… **Quick reference card** for content strategy (QUICK_ACTION_CARD.md)
- âœ… Modular architecture for easy expansion
- âœ… Well-documented code with comprehensive setup guides

### Key Insights Discovered:
- ğŸ“Š **Reddit 2,053x better engagement** than Twitter (5,172 vs 2.4 avg)
- â° **Best posting time**: 6:00 AM on Friday (10x better engagement)
- ğŸ“ **Optimal Reddit title length**: 50-100 characters (+22% engagement)
- ï¿½ **Sentiment impact**: Minimal (-0.030 correlation) - focus on information quality
- ï¿½ **Weekday advantage**: +86% better engagement than weekends
- #ï¸âƒ£ **Top hashtags**: #DigitalMarketing, #SEO, #AI
- ğŸ”‘ **Top keywords**: marketing, market, media, digital, content

### Potential Enhancements:
- ğŸ”® Schedule automated runs (using cron/Task Scheduler)
- ğŸ”® Data visualization dashboard
- ğŸ”® Historical trend analysis over time
- ğŸ”® Predictive engagement modeling
- ğŸ”® Automated posting to platforms
- ğŸ”® Export insights to PDF reports

---

## ğŸ› Issues Resolved

1. âœ… **Multiple Python versions conflict** - Fixed by using Python 3.13 explicitly
2. âœ… **Missing pip in Python 3.13** - Installed using `python -m ensurepip`
3. âœ… **Wrong Google Sheet ID** - Updated from private_key_id to actual sheet ID
4. âœ… **Service account not shared** - Shared sheet with service account email
5. âœ… **Environment variable caching** - Set correct variable in PowerShell session
6. âœ… **Timestamp serialization error** - Added datetime to string conversion
7. âœ… **Twitter rate limit** - Code handles automatically with wait_on_rate_limit=True

---

## âš ï¸ Known Limitations

1. **Twitter API Rate Limits:**
   - Free tier: Limited requests per 15-minute window
   - Solution: Multi-account rotation system (14 accounts) successfully handles this
   - Code automatically rotates accounts when limit is reached

2. **Reddit API Rate Limits:**
   - 60 requests per minute limit
   - Read-only access with current credentials
   - Solution: Code handles limits gracefully with delays

3. **Google Trends Rate Limits:**
   - Very aggressive rate limiting (~10-20 requests/hour)
   - 429 errors common with frequent requests
   - Solution: Space out requests, use sparingly for topic discovery

4. **Google Sheets:**
   - Maximum 10 million cells per spreadsheet
   - API quotas: 300 requests per 60 seconds per user
   - Solution: Batch operations, pagination

5. **Content Generation:**
   - Currently template-based (no AI LLM)
   - Uses real hashtags from collected data
   - 100% offline, no API costs

---

## ğŸ” Security Best Practices

âœ… **Implemented:**
- API keys stored in `.env` file
- `.env` and `service_account.json` in `.gitignore`
- Service account with minimal required permissions
- No credentials in code or repository

âš ï¸ **Recommendations:**
- Rotate API keys periodically
- Monitor API usage
- Use environment-specific credentials
- Enable 2FA on developer accounts
- Review Google Cloud audit logs

---

## ğŸ“š Documentation

- **README.md** - Complete setup guide with step-by-step instructions
- **PROJECT_SUMMARY.md** - This file (technical overview and architecture)
- **KEY_INSIGHTS.md** - Data analysis results and strategic recommendations
- **QUICK_ACTION_CARD.md** - Quick reference guide for content strategy
- **TWITTER_MULTI_ACCOUNT_SETUP.md** - Multi-account rotation setup guide
- **REDDIT_SETUP.md** - Reddit API setup guide
- **SLACK_INTEGRATION.md** - Slack webhook setup guide
- **Inline comments** - Every function documented with docstrings
- **Error messages** - Clear, actionable error messages with emoji indicators

---

## ğŸ“ Learning Outcomes

This project demonstrates:
- âœ… Multi-platform API integration (Twitter, Reddit, Google Trends, Slack)
- âœ… OAuth and various authentication methods
- âœ… **Multi-account rotation system** to handle rate limits
- âœ… Data collection and ETL pipeline design
- âœ… **Comprehensive exploratory data analysis (EDA)**
- âœ… **Sentiment analysis** using TextBlob
- âœ… **Temporal trends analysis** for optimal posting times
- âœ… **Statistical analysis** (correlations, outliers, distributions)
- âœ… Error handling and retry logic
- âœ… Rate limit management across different APIs
- âœ… Real-time notification systems (Slack webhooks)
- âœ… **LLM-based content generation** (Ollama/Llama 3.2)
- âœ… **Data-driven decision making** and business insights
- âœ… Modular code architecture
- âœ… Environment configuration management
- âœ… Version control best practices
- âœ… Comprehensive documentation skills

---

## ğŸ”„ Future Roadmap

### Phase 1: âœ… COMPLETE (Milestone 1)
- Multi-platform data collection (Twitter, Reddit, Google Trends)
- Multi-account Twitter rotation system (14 accounts)
- Google Sheets integration
- Slack notification system
- Comprehensive error handling
- **Achievement: 12,587 data points collected**

### Phase 2: âœ… COMPLETE (Milestone 2)
- Comprehensive EDA with 100% coverage
- Sentiment analysis (TextBlob integration)
- Temporal trends analysis (best posting times/days)
- Statistical analysis (correlations, outliers)
- **LLM-based content generation (Ollama/Llama 3.2)**
  - Separate generation file with Google Sheets integration
  - Slack notifications for generated content
- **Content optimization system**
  - Automatic LLM parameter selection (AI-optimized)
  - Manual LLM parameter selection (user-defined)
  - Content analysis & quality scoring (0-100)
  - Comparison between automatic vs manual optimization
  - Separate Google Sheets storage for optimized content
  - Slack notifications for optimization results
- **Dual worksheet system:**
  - 'Generated_Content' - All generated posts
  - 'Optimized_Content' - All optimizations with parameters
- Actionable insights documentation
- **Achievement: Free local AI, Separate generation/optimization, Parameter comparison, Reddit 2,053x better, 6 AM Friday optimal**

### Phase 3: ğŸ”® Planned (Milestone 3)
- Scheduled automated runs (daily/weekly)
- Data visualization dashboard
- Performance tracking over time
- Predictive engagement modeling
- Automated posting to platforms
- Real-time monitoring dashboard

### Phase 4: ğŸ”® Future
- Advanced ML models for engagement prediction
- Multi-platform cross-posting automation
- Real-time trend detection
- Competitive analysis features
- Custom reporting and export options

---

## ğŸ“ Support & Resources

### Official Documentation:
- [Google Sheets API](https://developers.google.com/sheets/api)
- [Twitter API v2](https://developer.twitter.com/en/docs/twitter-api)
- [Reddit API](https://www.reddit.com/dev/api/)
- [Google Trends (pytrends)](https://pypi.org/project/pytrends/)
- [Slack Incoming Webhooks](https://api.slack.com/messaging/webhooks)
- [Tweepy Documentation](https://docs.tweepy.org/)
- [PRAW Documentation](https://praw.readthedocs.io/)
- [gspread Documentation](https://docs.gspread.org/)

### Project Links:
- **Google Sheet:** [Social_Media_Engagement_Data](https://docs.google.com/spreadsheets/d/1VujT31YHr-gIlE2uWT6DyjPNEQXfAdmy60yTrsCAOYY)
- **Slack Workspace:** Social Data Collection (#social channel)
- **Twitter Developer Portal:** [developer.twitter.com](https://developer.twitter.com/)
- **Reddit Apps:** [reddit.com/prefs/apps](https://www.reddit.com/prefs/apps)
- **Google Cloud Console:** [console.cloud.google.com](https://console.cloud.google.com/)

### Key Documentation:
- **KEY_INSIGHTS.md** - Critical findings and recommendations
- **QUICK_ACTION_CARD.md** - Quick reference for content strategy

---

## âœ¨ Conclusion

This project successfully demonstrates a production-ready multi-platform social media data collection, analysis, and content generation pipeline. The system collected **12,587 data points**, performed comprehensive EDA (100% coverage), discovered actionable insights (Reddit 2,053x better, 6 AM Friday optimal), and generates AI-powered content using free local LLMs. The multi-account Twitter rotation system, advanced analytics capabilities, and Ollama-based content generation make this a complete end-to-end solution.

**Status:** âœ… **PRODUCTION READY - MILESTONES 1 & 2 COMPLETE**

**Platforms:** Twitter (14 accounts) âœ… | Reddit âœ… | Google Trends âœ… | Slack âœ…

**Analytics:** EDA âœ… | Sentiment Analysis âœ… | Temporal Trends âœ… | LLM Content Generation âœ…

**Key Achievement:** Discovered that Reddit provides 2,053x better engagement, posting at 6 AM Friday yields 10x better results, and implemented free local AI (Ollama/Llama 3.2) for creative content generation.

---

**Built with â¤ï¸ using Python, Google Sheets API, Twitter API, Reddit API, Google Trends, TextBlob, Slack, and Ollama (Llama 3.2)**

*Last Updated: November 9, 2025*
